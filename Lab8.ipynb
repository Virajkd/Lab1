{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Virajkd/Lab1/blob/main/Lab8.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-elvQEP-1JMV"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
        "from sklearn.linear_model import Perceptron\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "# A2: Hyperparameter tuning for Perceptron\n",
        "def tune_perceptron(X_train, y_train, X_test, y_test):\n",
        "    param_grid = {\n",
        "        'penalty': ['l2', 'l1', 'elasticnet'],\n",
        "        'alpha': [0.0001, 0.001, 0.01, 0.1],\n",
        "        'max_iter': [1000, 5000, 10000]\n",
        "    }\n",
        "    perceptron = Perceptron()\n",
        "    search = RandomizedSearchCV(perceptron, param_grid, n_iter=10, cv=3)\n",
        "    search.fit(X_train, y_train)\n",
        "    best_model = search.best_estimator_\n",
        "    predictions = best_model.predict(X_test)\n",
        "    return best_model, accuracy_score(y_test, predictions), precision_score(y_test, predictions, average='weighted'), recall_score(y_test, predictions, average='weighted'), f1_score(y_test, predictions, average='weighted')\n",
        "\n",
        "# A2: Hyperparameter tuning for MLP Network\n",
        "def tune_mlp_network(X_train, y_train, X_test, y_test):\n",
        "    param_grid = {\n",
        "        'hidden_layer_sizes': [(100,), (50, 50), (100, 50)],\n",
        "        'activation': ['relu', 'tanh'],\n",
        "        'solver': ['adam', 'sgd'],\n",
        "        'alpha': [0.0001, 0.001, 0.01]\n",
        "    }\n",
        "    mlp = MLPClassifier(max_iter=1000)\n",
        "    search = RandomizedSearchCV(mlp, param_grid, n_iter=10, cv=3)\n",
        "    search.fit(X_train, y_train)\n",
        "    best_model = search.best_estimator_\n",
        "    predictions = best_model.predict(X_test)\n",
        "    return best_model, accuracy_score(y_test, predictions), precision_score(y_test, predictions, average='weighted'), recall_score(y_test, predictions, average='weighted'), f1_score(y_test, predictions, average='weighted')\n",
        "\n",
        "# A3: Tabulation with various classifiers\n",
        "def compare_classifiers(X_train, y_train, X_test, y_test):\n",
        "    classifiers = {\n",
        "        'SVC': SVC(),\n",
        "        'DecisionTree': DecisionTreeClassifier(),\n",
        "        'RandomForest': RandomForestClassifier(),\n",
        "        'AdaBoost': AdaBoostClassifier(),\n",
        "        'XGBoost': XGBClassifier(use_label_encoder=False, eval_metric='mlogloss'),\n",
        "        'NaiveBayes': GaussianNB()\n",
        "    }\n",
        "    results = {}\n",
        "    for name, clf in classifiers.items():\n",
        "        clf.fit(X_train, y_train)\n",
        "        predictions = clf.predict(X_test)\n",
        "        results[name] = {\n",
        "            'Accuracy': accuracy_score(y_test, predictions),\n",
        "            'Precision': precision_score(y_test, predictions, average='weighted'),\n",
        "            'Recall': recall_score(y_test, predictions, average='weighted'),\n",
        "            'F1 Score': f1_score(y_test, predictions, average='weighted')\n",
        "        }\n",
        "    return results\n",
        "\n",
        "\n",
        "file_path = 'Scaled_CE_vector_v3.xlsx'\n",
        "df = pd.read_excel(file_path)\n",
        "df2=pd.read_excel(\"CE_vector_v3.xlsx\")\n",
        "# Separate the features (2304-dimensional summed vectors)\n",
        "X = df[[f'fused_vector_v{i}' for i in range(2304)]]\n",
        "\n",
        "# Extract the 'Final_Marks' column\n",
        "y = df2['Final_Marks']\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "# Call A2: Perceptron with hyperparameter tuning\n",
        "perceptron_model, acc_perc, prec_perc, rec_perc, f1_perc = tune_perceptron(X_train, y_train, X_test, y_test)\n",
        "print(f\"Perceptron Accuracy: {acc_perc}, Precision: {prec_perc}, Recall: {rec_perc}, F1 Score: {f1_perc}\")\n",
        "# Call A2: MLP with hyperparameter tuning\n",
        "mlp_model, acc_mlp, prec_mlp, rec_mlp, f1_mlp = tune_mlp_network(X_train, y_train, X_test, y_test)\n",
        "print(f\"MLP Accuracy: {acc_mlp}, Precision: {prec_mlp}, Recall: {rec_mlp}, F1 Score: {f1_mlp}\")\n",
        "# Call A3: Comparison with other classifiers\n",
        "results = compare_classifiers(X_train, y_train, X_test, y_test)\n",
        "print(\"Classifier Results:\")\n",
        "for clf, metrics in results.items():\n",
        "    print(f\"{clf} -> Accuracy: {metrics['Accuracy']}, Precision: {metrics['Precision']}, Recall: {metrics['Recall']}, F1 Score: {metrics['F1 Score']}\")from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
        "from sklearn.linear_model import Perceptron\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "from sklearn.datasets import load_iris\n",
        "import pandas as pd\n",
        "\n",
        "# Load sample dataset (replace with your project data)\n",
        "data = load_iris()\n",
        "X, y = data.data, data.target\n",
        "\n",
        "# Split the dataset\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Hyperparameter tuning for Perceptron using RandomizedSearchCV\n",
        "perceptron = Perceptron()\n",
        "param_grid = {\n",
        "    'penalty': ['l2', 'elasticnet'],\n",
        "    'alpha': [0.0001, 0.001, 0.01, 0.1, 1],\n",
        "    'max_iter': [1000, 2000, 5000]\n",
        "}\n",
        "random_search_perceptron = RandomizedSearchCV(perceptron, param_distributions=param_grid, n_iter=10, cv=5)\n",
        "random_search_perceptron.fit(X_train, y_train)\n",
        "\n",
        "# Evaluate Perceptron model\n",
        "y_pred_perceptron = random_search_perceptron.best_estimator_.predict(X_test)\n",
        "\n",
        "# Define other classifiers\n",
        "classifiers = {\n",
        "    'MLP': MLPClassifier(),\n",
        "    'SVM': SVC(),\n",
        "    'Decision Tree': DecisionTreeClassifier(),\n",
        "    'Random Forest': RandomForestClassifier(),\n",
        "    'AdaBoost': AdaBoostClassifier(),\n",
        "    'Naive Bayes': GaussianNB()\n",
        "}\n",
        "\n",
        "# Store results\n",
        "results = []\n",
        "\n",
        "# Function to evaluate models\n",
        "def evaluate_model(name, model):\n",
        "    model.fit(X_train, y_train)\n",
        "    y_pred = model.predict(X_test)\n",
        "    results.append({\n",
        "        'Model': name,\n",
        "        'Accuracy': accuracy_score(y_test, y_pred),\n",
        "        'Precision': precision_score(y_test, y_pred, average='weighted'),\n",
        "        'Recall': recall_score(y_test, y_pred, average='weighted'),\n",
        "        'F1-Score': f1_score(y_test, y_pred, average='weighted')\n",
        "    })\n",
        "\n",
        "# Evaluate Perceptron model\n",
        "evaluate_model('Perceptron', random_search_perceptron.best_estimator_)\n",
        "\n",
        "# Evaluate other classifiers\n",
        "for name, clf in classifiers.items():\n",
        "    evaluate_model(name, clf)\n",
        "\n",
        "# Tabulate results\n",
        "results_df = pd.DataFrame(results)\n",
        "print(results_df)"
      ]
    }
  ]
}